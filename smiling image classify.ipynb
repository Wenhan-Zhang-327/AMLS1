{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, csv_file, txt_file, root_dir, transform=None):\n",
    "        self.index = pd.read_csv(csv_file)\n",
    "        self.labels = np.loadtxt(txt_file)[:,3]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir, self.index.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        image = image.astype('float')\n",
    "        labels = self.labels[idx]\n",
    "        labels = labels.astype('long').reshape(-1)\n",
    "        sample = {'image':image, 'label':labels}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        label = (label + 1) / 2\n",
    "        return {'image':torch.FloatTensor(image),\n",
    "                 'label':torch.LongTensor(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = FaceDataset(csv_file='img/label.csv', txt_file='img/labelss.txt',\n",
    "                                  root_dir='img/', transform=transforms.Compose([\n",
    "    ToTensor()\n",
    "]))\n",
    "train_size = 4500\n",
    "test_size = 500\n",
    "batch_size = 150\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(transformed_dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立卷积神经网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 4, 1)\n",
    "        self.conv3 = nn.Conv2d(20, 50, 3, 1)\n",
    "        self.fc1 = nn.Linear(25*20*50, 10000)\n",
    "        self.fc2 = nn.Linear(10000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.fc4 = nn.Linear(100, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 25*20*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数、模型、优化器\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "model = Net()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for idx, sample in enumerate(train_loader): # idx:字典的批序号，sample:第idx批字典\n",
    "        data = sample['image'] # data:tensor格式float32, 30 * 3 * 94 * 94\n",
    "        target = sample['label'].view(-1) # target:tensor格式， 30 * 1\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "        pred = model(data) # pred:tensor格式， 30 * 1\n",
    "        loss = F.nll_loss(pred, target) # loss:tensor格式标量\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #torch.save()\n",
    "        print(\"Train Epoch:{}, iteration:{}, Loss:{}\".format(epoch, idx, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试函数\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    correct = 0.\n",
    "    with torch.no_grad():\n",
    "        for idx, sample in enumerate(test_loader): # idx:字典的批序号，sample:第idx批字典\n",
    "            data = sample['image'] # data:tensor格式float32, 1 * 3 * 94 * 94\n",
    "            target = sample['label'].view(-1) # target:tensor格式标量\n",
    "            data = torch.tensor(data, dtype=torch.float32)\n",
    "            output = model(data) # output:tensor格式标量\n",
    "            total_loss = F.nll_loss(output, target, reduction = 'sum').item() # total_loss:tensor格式标量\n",
    "            pred = output.argmax(dim = 1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    total_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset) * 100\n",
    "    print(\"Test Loss:{}, Test Accuracy:{}\".format(total_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\lab1\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:0, iteration:0, Loss:0.6931928992271423\n",
      "Train Epoch:0, iteration:1, Loss:0.9958832859992981\n",
      "Train Epoch:0, iteration:2, Loss:0.8011842966079712\n",
      "Train Epoch:0, iteration:3, Loss:0.7193429470062256\n",
      "Train Epoch:0, iteration:4, Loss:0.695889413356781\n",
      "Train Epoch:0, iteration:5, Loss:0.6959963440895081\n",
      "Train Epoch:0, iteration:6, Loss:0.6926345229148865\n",
      "Train Epoch:0, iteration:7, Loss:0.692929744720459\n",
      "Train Epoch:0, iteration:8, Loss:0.6942481994628906\n",
      "Train Epoch:0, iteration:9, Loss:0.6933512091636658\n",
      "Train Epoch:0, iteration:10, Loss:0.6907745599746704\n",
      "Train Epoch:0, iteration:11, Loss:0.6905175447463989\n",
      "Train Epoch:0, iteration:12, Loss:0.6914636492729187\n",
      "Train Epoch:0, iteration:13, Loss:0.695116400718689\n",
      "Train Epoch:0, iteration:14, Loss:0.688738226890564\n",
      "Train Epoch:0, iteration:15, Loss:0.6972552537918091\n",
      "Train Epoch:0, iteration:16, Loss:0.69049072265625\n",
      "Train Epoch:0, iteration:17, Loss:0.6873247623443604\n",
      "Train Epoch:0, iteration:18, Loss:0.6892884969711304\n",
      "Train Epoch:0, iteration:19, Loss:0.6875362396240234\n",
      "Train Epoch:0, iteration:20, Loss:0.6873936057090759\n",
      "Train Epoch:0, iteration:21, Loss:0.6833291053771973\n",
      "Train Epoch:0, iteration:22, Loss:0.6877702474594116\n",
      "Train Epoch:0, iteration:23, Loss:0.6821537017822266\n",
      "Train Epoch:0, iteration:24, Loss:0.6845008730888367\n",
      "Train Epoch:0, iteration:25, Loss:0.6919853687286377\n",
      "Train Epoch:0, iteration:26, Loss:0.683563232421875\n",
      "Train Epoch:0, iteration:27, Loss:0.6807353496551514\n",
      "Train Epoch:0, iteration:28, Loss:0.6839842200279236\n",
      "Train Epoch:0, iteration:29, Loss:0.6787787675857544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\lab1\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.682152099609375, Test Accuracy:59.8\n",
      "Train Epoch:1, iteration:0, Loss:0.6807897686958313\n",
      "Train Epoch:1, iteration:1, Loss:0.6684948801994324\n",
      "Train Epoch:1, iteration:2, Loss:0.6798608899116516\n",
      "Train Epoch:1, iteration:3, Loss:0.6702999472618103\n",
      "Train Epoch:1, iteration:4, Loss:0.6658823490142822\n",
      "Train Epoch:1, iteration:5, Loss:0.6695975661277771\n",
      "Train Epoch:1, iteration:6, Loss:0.6615840196609497\n",
      "Train Epoch:1, iteration:7, Loss:0.6560905575752258\n",
      "Train Epoch:1, iteration:8, Loss:0.6502979397773743\n",
      "Train Epoch:1, iteration:9, Loss:0.6483038663864136\n",
      "Train Epoch:1, iteration:10, Loss:0.6769174337387085\n",
      "Train Epoch:1, iteration:11, Loss:0.6544761061668396\n",
      "Train Epoch:1, iteration:12, Loss:0.6708042621612549\n",
      "Train Epoch:1, iteration:13, Loss:0.6410583257675171\n",
      "Train Epoch:1, iteration:14, Loss:0.6459581255912781\n",
      "Train Epoch:1, iteration:15, Loss:0.6406623125076294\n",
      "Train Epoch:1, iteration:16, Loss:0.6476373672485352\n",
      "Train Epoch:1, iteration:17, Loss:0.6209756731987\n",
      "Train Epoch:1, iteration:18, Loss:0.6305745840072632\n",
      "Train Epoch:1, iteration:19, Loss:0.6213639974594116\n",
      "Train Epoch:1, iteration:20, Loss:0.6189075112342834\n",
      "Train Epoch:1, iteration:21, Loss:0.6210446953773499\n",
      "Train Epoch:1, iteration:22, Loss:0.6015598773956299\n",
      "Train Epoch:1, iteration:23, Loss:0.6055800318717957\n",
      "Train Epoch:1, iteration:24, Loss:0.5721324682235718\n",
      "Train Epoch:1, iteration:25, Loss:0.5762795805931091\n",
      "Train Epoch:1, iteration:26, Loss:0.5801993012428284\n",
      "Train Epoch:1, iteration:27, Loss:0.6949552297592163\n",
      "Train Epoch:1, iteration:28, Loss:0.7540779113769531\n",
      "Train Epoch:1, iteration:29, Loss:0.6752138733863831\n",
      "Test Loss:0.65385888671875, Test Accuracy:70.19999999999999\n",
      "Train Epoch:2, iteration:0, Loss:0.6534811854362488\n",
      "Train Epoch:2, iteration:1, Loss:0.6494113802909851\n",
      "Train Epoch:2, iteration:2, Loss:0.6452163457870483\n",
      "Train Epoch:2, iteration:3, Loss:0.634149432182312\n",
      "Train Epoch:2, iteration:4, Loss:0.6241528391838074\n",
      "Train Epoch:2, iteration:5, Loss:0.6234331727027893\n",
      "Train Epoch:2, iteration:6, Loss:0.6060415506362915\n",
      "Train Epoch:2, iteration:7, Loss:0.5915395617485046\n",
      "Train Epoch:2, iteration:8, Loss:0.5463848114013672\n",
      "Train Epoch:2, iteration:9, Loss:0.5179958343505859\n",
      "Train Epoch:2, iteration:10, Loss:0.5177578926086426\n",
      "Train Epoch:2, iteration:11, Loss:0.57949298620224\n",
      "Train Epoch:2, iteration:12, Loss:0.956651508808136\n",
      "Train Epoch:2, iteration:13, Loss:0.702234148979187\n",
      "Train Epoch:2, iteration:14, Loss:0.7051337361335754\n",
      "Train Epoch:2, iteration:15, Loss:0.6929270625114441\n",
      "Train Epoch:2, iteration:16, Loss:0.6824250221252441\n",
      "Train Epoch:2, iteration:17, Loss:0.6809629201889038\n",
      "Train Epoch:2, iteration:18, Loss:0.6887000799179077\n",
      "Train Epoch:2, iteration:19, Loss:0.6831334233283997\n",
      "Train Epoch:2, iteration:20, Loss:0.6792108416557312\n",
      "Train Epoch:2, iteration:21, Loss:0.6787413358688354\n",
      "Train Epoch:2, iteration:22, Loss:0.6722997426986694\n",
      "Train Epoch:2, iteration:23, Loss:0.6656264066696167\n",
      "Train Epoch:2, iteration:24, Loss:0.6647014617919922\n",
      "Train Epoch:2, iteration:25, Loss:0.6618902683258057\n",
      "Train Epoch:2, iteration:26, Loss:0.6583981513977051\n",
      "Train Epoch:2, iteration:27, Loss:0.6530728936195374\n",
      "Train Epoch:2, iteration:28, Loss:0.6498754620552063\n",
      "Train Epoch:2, iteration:29, Loss:0.6370295882225037\n",
      "Test Loss:0.6385936279296875, Test Accuracy:73.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
